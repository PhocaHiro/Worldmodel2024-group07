{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/PhocaHiro/s4_Phoca.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /content/s4\n",
    "# ============= Set Up =============\n",
    "# Requirements\n",
    "!conda install pytorch==1.13.1 torchvision==0.14.1 torchaudio==0.13.1 pytorch-cuda=11.6 -c pytorch -c nvidia\n",
    "!pip install -r requirements.txt\n",
    "# Structured Kernels\n",
    "%cd extensions/kernels/\n",
    "!python setup.py install\n",
    "%cd /content/s4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CUDA extension for structured kernels (Cauchy and Vandermonde multiplication) not found. Install by going to extensions/kernels/ and running `python setup.py install`, for improved speed and memory efficiency. Note that the kernel changed for state-spaces 4.0 and must be recompiled.\n",
      "Falling back on slow Cauchy and Vandermonde kernel. Install at least one of pykeops or the CUDA extension for better speed and memory efficiency.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[KeOps] Warning : Cuda libraries were not detected on the system or could not be loaded ; using cpu only mode\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gomag\\anaconda3\\envs\\gymenv2\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "\n",
    "from models.s4.s4 import S4Block as S4  # Can use full version instead of minimal S4D standalone below\n",
    "from models.s4.s4d import S4D\n",
    "from tqdm.auto import tqdm\n",
    "import copy\n",
    "\n",
    "# Dropout broke in PyTorch 1.11\n",
    "if tuple(map(int, torch.__version__.split('.')[:2])) == (1, 11):\n",
    "    print(\"WARNING: Dropout is bugged in PyTorch 1.11. Results may be worse.\")\n",
    "    dropout_fn = nn.Dropout\n",
    "if tuple(map(int, torch.__version__.split('.')[:2])) >= (1, 12):\n",
    "    dropout_fn = nn.Dropout1d\n",
    "else:\n",
    "    dropout_fn = nn.Dropout2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "best_acc = 0  # best test accuracy\n",
    "start_epoch = 0  # start from epoch 0 or last checkpoint epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ハイパラの設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import datetime\n",
    "\n",
    "lr = 0.001\n",
    "weight_decay = 0.01\n",
    "num_workers = 4\n",
    "batch_size = 8\n",
    "d_model = 512\n",
    "d_mlp = 512\n",
    "prenorm = True\n",
    "dropout = 0.1\n",
    "grad_clip = 1000\n",
    "\n",
    "hyperparameters = {\n",
    "    \"lr\": lr,\n",
    "    \"weight_decay\": weight_decay,\n",
    "    \"num_workers\":  num_workers,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"d_model\": d_model,\n",
    "    \"d_mlp\": d_mlp,\n",
    "    \"prenorm\": prenorm,\n",
    "    \"dropout\": dropout,\n",
    "    \"grad_clip\": grad_clip,\n",
    "}\n",
    "\n",
    "# ハイパラの種類が今後増える可能性を踏まえ、ファイル名にversionを記載する(hyparaVxxとなるように)\n",
    "current_time = datetime.datetime.now()\n",
    "current_time_str = current_time.strftime(\"%Y%m%d_%H%M\")\n",
    "with open(f'hyparams/hyparaV1_{current_time_str}.json', 'w') as f:\n",
    "    json.dump(hyperparameters, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# S4Block (p26 Figure21参照)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class S4Block(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        d_model=256,\n",
    "        d_mlp = 512,\n",
    "        n_layers=2,\n",
    "        dropout=0.2,\n",
    "        prenorm=True,\n",
    "    ):\n",
    "        super(S4Block, self).__init__()\n",
    "\n",
    "        self.prenorm = prenorm\n",
    "\n",
    "        # Stack S4 layers as residual blocks\n",
    "        self.s4_layers = nn.ModuleList()\n",
    "        self.norms = nn.ModuleList()\n",
    "        self.dropouts1 = nn.ModuleList()\n",
    "        self.linears = nn.ModuleList()\n",
    "        self.glus = nn.ModuleList()\n",
    "        self.dropouts2= nn.ModuleList()\n",
    "        for _ in range(n_layers):\n",
    "            self.s4_layers.append(\n",
    "                S4D(d_model, dropout=0.0, transposed=True, lr=min(0.001, lr)) # ドロップアウトはとりあえず使わない設定\n",
    "            )\n",
    "            self.linears.append(nn.Linear(d_model, d_model))\n",
    "            self.norms.append(nn.LayerNorm(d_model))\n",
    "            self.dropouts1.append(dropout_fn(dropout))\n",
    "            self.glus.append(nn.GLU())   #TODO: これ何？\n",
    "            self.dropouts2.append(dropout_fn(dropout))\n",
    "\n",
    "        self.norm_mlp = nn.ModuleList([\n",
    "            nn.LayerNorm(d_model),\n",
    "            nn.Linear(d_model, d_mlp),\n",
    "            nn.GELU(),\n",
    "            dropout_fn(dropout),\n",
    "            nn.Linear(d_model, d_mlp),\n",
    "            dropout_fn(dropout)])\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Input x is shape (B, L, d_model)\n",
    "        \"\"\"\n",
    "        x = x.transpose(-1, -2)  # (B, L, d_model) -> (B, d_model, L)\n",
    "        for s4, norm, dropout1, linear, glu, dropout2 in \\\n",
    "            zip(self.s4_layers, self.norms, self.dropouts1, self.linears, self.glus, self.dropouts2):\n",
    "            # Each iteration of this loop will map (B, d_model, L) -> (B, d_model, L)\n",
    "\n",
    "            z = x\n",
    "            if self.prenorm:\n",
    "                # Prenorm\n",
    "                z = norm(z.transpose(-1, -2)).transpose(-1, -2)\n",
    "\n",
    "            # Apply S4 block: we ignore the state input and output\n",
    "            z, _ = s4(z)\n",
    "\n",
    "            # Dropout on the output of the S4 block\n",
    "            z = dropout1(z)\n",
    "\n",
    "            # Mixing informations\n",
    "            z = linear(z.transpose(-1, -2)).transpose(-1, -2)\n",
    "            z = glu(z)\n",
    "            z = dropout2(z)\n",
    "\n",
    "            # Residual connection\n",
    "            x = z + x\n",
    "\n",
    "            if not self.prenorm:\n",
    "                # Postnorm\n",
    "                x = norm(x.transpose(-1, -2)).transpose(-1, -2)\n",
    "\n",
    "        x = x.transpose(-1, -2)  # (B, d_model, L) -> (B, L, d_model)\n",
    "\n",
    "        #TODO: x_にも操作が反映されてたりしないか確認する\n",
    "        x_ = x\n",
    "        x = x_ + self.norm_mlp(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoder(画像にする必要はあるか？評価する上では画像にする必要はありそうだけど実際にモデルとしては軽いほうがいい)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \"\"\"\n",
    "    (input_dim, 64, 64)の画像を(1024,)のベクトルに変換する\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim=3, # grayscaleなら1\n",
    "        hidden_dim=30,\n",
    "    ):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.cv1 = nn.Conv2d(input_dim, 32, kernel_size=4, stride=2) # (input_dim, 64, 64) -> (32, 31, 31)\n",
    "        self.cv2 = nn.Conv2d(32, 64, kernel_size=4, stride=2) # (32, 31, 31) -> (64, 14, 14)\n",
    "        self.cv3 = nn.Conv2d(64, 128, kernel_size=4, stride=2) # (64, 14, 14) -> (128, 6, 6)\n",
    "        self.cv4 = nn.Conv2d(128, 256, kernel_size=4, stride=2) # (128, 6, 6) -> (256, 2, 2)\n",
    "        self.mean_posterior = nn.Linear(1024, hidden_dim)\n",
    "\n",
    "    def forward(self, obs):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        obs : torch.Tensor (batch_size, L, input_dim, 64, 64)\n",
    "            環境から得られた観測画像\n",
    "        \n",
    "        Returns\n",
    "        ----------\n",
    "         : torch.Tensor (batch_size, L, 1024)\n",
    "            観測画像を1024次元に埋め込んだもの\n",
    "        \"\"\"\n",
    "        hidden = F.relu(self.cv1(obs))\n",
    "        hidden = F.relu(self.cv2(hidden))\n",
    "        hidden = F.relu(self.cv3(hidden))\n",
    "        embedded_obs = F.relu(self.cv4(hidden)).reshape(hidden.size(0), -1)\n",
    "        return embedded_obs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gymenv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
